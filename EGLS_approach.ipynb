{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e7f1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries to import\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import sys\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from nltk.corpus import words\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca742625",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae701164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We use the nltk corpus to generate the words we're going to use as reference\n",
    "dicto = words.words()\n",
    "\n",
    "def post_process(string):\n",
    "\n",
    "    # The plan is to split the file by lines first, then split the lines into words to only keep the ones contained in the\n",
    "    # English dictionnary.\n",
    "    stringlist2 = string.split(\"\\n\")\n",
    "    \n",
    "    # We're going to iterate through all the lines,\n",
    "    for j in range(0, len(stringlist2)):\n",
    "        # Split the line into words,\n",
    "        stringlist = stringlist2[j].split()\n",
    "        # Introduce a garbage counter\n",
    "        isGarbage = 0\n",
    "        # We're iterating through all the words\n",
    "        for i in range(0, len(stringlist)):\n",
    "            if stringlist[i].isalpha() and stringlist[i] is not None:\n",
    "                # If the word isn't in the dictionnary we add one to the garbage counter\n",
    "                if stringlist[i].lower() not in dicto and stringlist[i][:-1] not in dicto:\n",
    "                    isGarbage += 1\n",
    "        # If there are enough garbage words in a sentence, the program deletes the sentence entirely.\n",
    "        if isGarbage >= 2:\n",
    "            string = string.replace(stringlist2[j], \"\")\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4612b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the lists of all the pdfs\n",
    "list_pdfs = os.listdir('CanDev_Scanned_Documents-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e77234b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes one pdf at a time from list_pdfs, saves the pdf as images (i.e an eight page pdf will have 8 png files), gets the horizontal lines\n",
    "#from the png files, compares the number of horizontal lines to a threshold, if it is greater, then text is extracted from that image, the \n",
    "#text is stored as a JSON object.\n",
    "#the idea for such implementation is that pages with tables have higher number of horizontal lines. So getting such lines will help us to get \n",
    "#pages with tables.\n",
    "for PDF_file in list_pdfs:\n",
    "    #converts pdf to image files\n",
    "    pages = convert_from_path('CanDev_Scanned_Documents-master/'+PDF_file, 500, poppler_path=r'poppler\\poppler-0.68.0\\bin')\n",
    "    image_counter = 1\n",
    "    \n",
    "    #getting the image files one at a time and storing them as png files.\n",
    "    for page in pages:\n",
    "        filename = \"Shared/page_\"+str(image_counter)+\".png\"\n",
    "        page.save(filename, 'PNG')\n",
    "        image_counter = image_counter + 1\n",
    "        \n",
    "    filelimit = image_counter-1\n",
    "    \n",
    "    #taking images one by one and performing operations\n",
    "    for i in range(1, filelimit + 1):\n",
    "        filename = \"Shared/page_\"+str(i)+\".png\"\n",
    "        #reads the image using OpenCV and converting it to numpy array with horizontal lines\n",
    "        src = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "        gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bitwise_not(gray)\n",
    "        bw = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \\\n",
    "                                        cv2.THRESH_BINARY, 15, -2)\n",
    "        horizontal = np.copy(bw)\n",
    "        cols = horizontal.shape[1]\n",
    "        horizontal_size = cols // 30\n",
    "        \n",
    "        # Create structure element for extracting horizontal lines through morphology operations\n",
    "        horizontalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontal_size, 1))\n",
    "        \n",
    "        # Apply morphology operations\n",
    "        horizontal = cv2.erode(horizontal, horizontalStructure)\n",
    "        horizontal = cv2.dilate(horizontal, horizontalStructure)\n",
    "        \n",
    "        #counting the number of horizontal lines based on a theshold value\n",
    "        lines = cv2.HoughLinesP(horizontal,rho = 1,theta = 1*np.pi/180,threshold = 1500,minLineLength = 10,maxLineGap = 10)\n",
    "        \n",
    "        #lines variable can be empty if no lines are detected so checking if the variable lines is an np array or not\n",
    "        #if not then it would be disregarded as no lines were detected\n",
    "        if isinstance(lines, np.ndarray) == True:\n",
    "            #checking if number of horizontal lines is greater thatn a thershold value\n",
    "            if len(lines)>25:\n",
    "                \n",
    "                #getting the text out of the images if it thinks it is a table\n",
    "                text = str(((pytesseract.image_to_string(Image.open(filename), config='--psm 6'))))\n",
    "                text = text.replace('|', '')\n",
    "                \n",
    "                #performing some post_processing steps to get rid of garbagge words\n",
    "                text = post_process(text)\n",
    "                \n",
    "                #splitting the string based on new lines\n",
    "                lst = text.split('\\n')\n",
    "                \n",
    "                #removing the first and last items from the list as it mainly contains page number\n",
    "                lst = lst[1:-1]\n",
    "                \n",
    "                #considering the first two lines as title of the table\n",
    "                title = lst[0] + lst[1]\n",
    "                \n",
    "                #the rest of the lines will be considered for the contents of the table\n",
    "                lst = lst[2:]\n",
    "                \n",
    "                #creating an empty dictionary and storing the table rows in key value pair (row#, content of the row)\n",
    "                a_dict = {}\n",
    "                a_dict[\"Title\"] = title\n",
    "                count = 0\n",
    "                for i in lst:\n",
    "                    if len(i)>3:\n",
    "                        count+=1\n",
    "                        key = \"row \"+str(count)\n",
    "                        a_dict[key] = i\n",
    "                \n",
    "                #converting the dictionary into a JSON object\n",
    "                json_object = json.dumps(a_dict, indent = 4)\n",
    "                \n",
    "                #saving the JSON files\n",
    "                with open('Shared/'+PDF_file[0:-4] +'_' +filename[7:-4] + '.json', 'w') as f:\n",
    "                    json.dump(json_object, f)\n",
    "                    \n",
    "    #removing the png files as we just need the content from the tables\n",
    "    for file in os.listdir('Shared'): \n",
    "        if file.endswith('.png'):\n",
    "            os.remove('Shared/'+file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e079922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to rotate a page if it has got an angle of 90 degrees\n",
    "def rotate_bound(image, angle):\n",
    "    \"\"\"Rotate image with the given angle\n",
    "    :param type image: input image\n",
    "    :param type angle: Angle to be rotated\n",
    "    :return: rotated image\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    (h, w) = image.shape[:2]\n",
    "    ### centroid\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "    ### creating rotation matrix\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    "    return cv2.warpAffine(image, M, (nW, nH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is another approach to get the tables from the images. In this approach we have counted the number of numeric values in a page and see if it \n",
    "#crosses a threshold value. Our motivation here is that the images with tables have higher number of numeric values like 12,300 or 12,300.00\n",
    "#or decimal or integer values. Also, in this approach we have considered the pages which have an angle of 90 degree. We have rotated such images\n",
    "#because we have checked that tesseract can not extract text correctly from such images. \n",
    "for PDF_file in list_pdfs:\n",
    "    pages = convert_from_path('CanDev_Scanned_Documents-master/'+PDF_file, 500, poppler_path=r'poppler\\poppler-0.68.0\\bin')\n",
    "    image_counter = 1\n",
    "    #count = 0\n",
    "    for page in pages:\n",
    "        filename = \"num_count/page_\"+str(image_counter)+\".png\"\n",
    "        page.save(filename, 'PNG')\n",
    "        image_counter = image_counter + 1\n",
    "        \n",
    "    filelimit = image_counter-1\n",
    "    for i in range(1, filelimit + 1):\n",
    "        filename = \"num_count/page_\"+str(i)+\".png\"\n",
    "        #count+=1\n",
    "        \n",
    "        image=cv2.imread(filename)\n",
    "        \n",
    "        #checking if the angle of the image is 90 degree.\n",
    "        newdata=pytesseract.image_to_osd(image)\n",
    "        angle=re.search('(?<=Rotate: )\\d+', newdata).group(0)\n",
    "        print('osd angle:',angle)\n",
    "        if angle=='90':\n",
    "            #if the angle is 90 degree then it is rotaing the image\n",
    "            skew_corrected_image=rotate_bound(image,float(angle))\n",
    "        else:\n",
    "            skew_corrected_image = image\n",
    "        \n",
    "        #getting the text from an image to count the numeric values in it\n",
    "        text_tmp = str(((pytesseract.image_to_string(skew_corrected_image, config='--psm 6'))))\n",
    "        \n",
    "        '''\n",
    "        (finds commas) 12,300 or 12,300.00\n",
    "        '[\\d]+[.,\\d]+'\n",
    "        \n",
    "        (finds floats) 0.123 or .123\n",
    "        '[\\d]*[.][\\d]+'\n",
    "        \n",
    "        (finds integers) 123\n",
    "        '[\\d]+'\n",
    "        '''\n",
    "        \n",
    "        p = '[\\d]+[.,\\d]+|[\\d]*[.][\\d]+|[\\d]+'\n",
    "        count = 0\n",
    "        if re.search(p, text_tmp) is not None:\n",
    "            #using re to get the numeric values from the string and counting the number of such occurences\n",
    "            for catch in re.finditer(p, text_tmp):\n",
    "                count+=1\n",
    "                \n",
    "        #if the count is greater than 30 then it will be considered as a table\n",
    "        if count>30:\n",
    "            \n",
    "            #getting the text out of the images if it thinks it is a table\n",
    "            text = str(((pytesseract.image_to_string(skew_corrected_image, config='--psm 6'))))\n",
    "            text = text.replace('|', '')\n",
    "            \n",
    "            #performing some post_processing steps to get rid of garbagge words\n",
    "            text = post_process(text)\n",
    "                \n",
    "            #splitting the string based on new lines\n",
    "            lst = text.split('\\n')\n",
    "            \n",
    "            #removing the first and last items from the list as it mainly contains page number\n",
    "            lst = lst[1:-1]\n",
    "            \n",
    "            #considering the first two lines as title of the table\n",
    "            title = lst[0] + lst[1]\n",
    "            \n",
    "            #the rest of the lines will be considered for the contents of the table\n",
    "            lst = lst[2:]\n",
    "            \n",
    "            #creating an empty dictionary and storing the table rows in key value pair (row#, content of the row)\n",
    "            a_dict = {}\n",
    "            a_dict[\"Title\"] = title\n",
    "            count = 0\n",
    "            for i in lst:\n",
    "                if len(i)>3:\n",
    "                    count+=1\n",
    "                    key = \"row \"+str(count)\n",
    "                    a_dict[key] = i\n",
    "            \n",
    "             #converting the dictionary into a JSON object\n",
    "            json_object = json.dumps(a_dict, indent = 4)\n",
    "            \n",
    "            #saving the JSON files\n",
    "            with open('num_count/'+PDF_file[0:-4] +'_' +filename[10:-4] + '.json', 'w') as f:\n",
    "                json.dump(json_object, f)\n",
    "                \n",
    "    #removing the png files as we just need the content from the tables\n",
    "    for file in os.listdir('num_count'): \n",
    "        if file.endswith('.png'):\n",
    "            os.remove('num_count/'+file) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (candevbk)",
   "language": "python",
   "name": "candevbk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
